- 先减少“拿多少数据”：服务端分页/游标、字段裁剪、按需过滤与聚合，避免把“全量原始数据”推给前端。
- 再优化“怎么传”：压缩、流式输送、二进制/紧凑格式，降低带宽与首包等待。
- 同时优化“怎么展示”：列表虚拟化、分段渲染、惰性加载，避免一次性往 DOM 塞入海量节点。
- 最后优化“怎么算”：分片计算、Web Worker、增量解析，避免长任务阻塞主线程。
- 全程加“缓存与并发控制”：LRU 缓存、请求去重/限流/取消，避免重复工作和内存压力。

客户端展示
- 列表虚拟化：只渲染视区附近的少量节点；固定高可用“平移 + 占位”方案。
- 无限加载：Intersection Observer + rootMargin 预取，进入视区前拉下一页。
- 分段渲染：把 1e5 条数据按 500/1000 条一批插入，避免长任务阻塞。
- 骨架与占位：首屏先渲染骨架，提升感知速度；加载中保持稳定布局避免抖动。

客户端计算
- 分片计算：把重计算拆成小批次，批间让出事件循环或空闲时间，避免长任务。
- Web Worker：把排序/聚合/格式化丢到 Worker；主线程只做请求与渲染。
- 增量解析：NDJSON/流式响应边读边 parse，少用一次性 JSON.parse 巨对象。
- 采样与降采样：图表海量点先做采样/桶聚合（如 LTTB/等宽桶），保障交互流畅。

缓存与并发控制
- 内存 LRU：把近期页或查询结果做 LRU 缓存，溢出自动淘汰，避免内存膨胀。
- 请求去重与限流：相同查询只发一次；高频场景设并发上限与排队策略。
- 取消与回收：滚动/切页时取消在途请求；组件卸载清理定时器与引用。
- 持久化缓存：大数据离线访问可用 IndexedDB（分块存储），注意配额管理。

监控与回退
- 关键指标：长任务占比、TBT、内存占用、失败率、平均页渲染时长。
- 保护阈值：超阈值自动降级（更小页大小/更弱视觉效果/只显摘要）。
- 逐步加载：失败或超时部分渲染，其它延后；错误信息与重试入口清晰。


/**
 * observeInfiniteScroll
 * 功能：在“触底哨兵”进入视区时触发加载更多，支持预取与并发防抖
 * @param sentinel 哨兵元素
 * @param onLoadMore 加载更多回调，返回是否还有更多
 * @param options IntersectionObserver 配置（如 rootMargin 预取 '200px 0'）
 * @returns 解绑函数
 */
export function observeInfiniteScroll(
  sentinel: HTMLElement,
  onLoadMore: () => Promise<boolean>,
  options: IntersectionObserverInit = { rootMargin: '150px 0px' }
): () => void {
  let inFlight = false
  let hasMore = true
  const io = new IntersectionObserver(async entries => {
    if (!hasMore || inFlight) return
    if (entries.some(e => e.isIntersecting)) {
      inFlight = true
      try { hasMore = await onLoadMore() } finally { inFlight = false }
    }
  }, options)
  io.observe(sentinel)
  return () => io.disconnect()
}

/**
 * createVirtualScroller
 * 功能：固定行高的列表虚拟化，仅渲染视区附近的条目
 * @param container 容器元素（需有固定高度，overflow: auto）
 * @param totalCount 总条数
 * @param itemHeight 单条高度（px）
 * @param overscan 额外提前/延后渲染的条数
 * @param render 渲染函数，接收 [start,end] 返回 DocumentFragment/Node[]
 * @returns 清理函数
 */
export function createVirtualScroller(
  container: HTMLElement,
  totalCount: number,
  itemHeight: number,
  overscan: number,
  render: (start: number, end: number) => DocumentFragment | Node[]
): () => void {
  container.style.position = 'relative'
  container.style.overflow = 'auto'
  const spacer = document.createElement('div')
  spacer.style.height = `${totalCount * itemHeight}px`
  const inner = document.createElement('div')
  inner.style.position = 'absolute'
  inner.style.top = '0'
  inner.style.left = '0'
  inner.style.right = '0'
  container.append(spacer, inner)

  const paint = () => {
    const vh = container.clientHeight
    const scrollTop = container.scrollTop
    const visible = Math.ceil(vh / itemHeight)
    const start = Math.max(0, Math.floor(scrollTop / itemHeight) - overscan)
    const end = Math.min(totalCount - 1, start + visible + overscan * 2 - 1)
    inner.style.transform = `translateY(${start * itemHeight}px)`
    inner.innerHTML = ''
    const frag = render(start, end)
    if (Array.isArray(frag)) frag.forEach(n => inner.appendChild(n))
    else inner.appendChild(frag)
  }
  container.addEventListener('scroll', paint, { passive: true })
  window.addEventListener('resize', paint)
  paint()
  return () => {
    container.removeEventListener('scroll', paint)
    window.removeEventListener('resize', paint)
    inner.remove()
    spacer.remove()
  }
}


/**
 * processInChunks
 * 功能：把大数组按批次处理，每批后让出主线程以提升交互流畅度
 * @param items 数据数组
 * @param chunkSize 每批处理数量
 * @param processChunk 处理函数，输入该批数据
 * @param onProgress 进度回调（已处理数量/总数）
 */
export async function processInChunks<T>(
  items: T[],
  chunkSize: number,
  processChunk: (batch: T[], batchIndex: number) => Promise<void> | void,
  onProgress?: (done: number, total: number) => void
): Promise<void> {
  const total = items.length
  for (let i = 0; i < total; i += chunkSize) {
    const batch = items.slice(i, i + chunkSize)
    await processChunk(batch, Math.floor(i / chunkSize))
    onProgress?.(Math.min(i + chunkSize, total), total)
    await new Promise(res => setTimeout(res, 0)) // 让出事件循环
  }
}

/**
 * createConcurrencyLimiter
 * 功能：限制并发执行的异步任务数，超出部分排队
 * @param maxConcurrency 并发上限
 * @returns 包装执行函数 limiter(fn)
 */
export function createConcurrencyLimiter(maxConcurrency: number) {
  let active = 0
  const queue: Array<() => void> = []

  const next = () => {
    active--
    const q = queue.shift()
    q?.()
  }

  return async function<T>(task: () => Promise<T>): Promise<T> {
    if (active >= maxConcurrency) {
      await new Promise<void>(res => queue.push(res))
    }
    active++
    try { return await task() } finally { next() }
  }
}

/**
 * createLruCache
 * 功能：简单 LRU 缓存（按最近使用淘汰），避免内存膨胀
 * @param maxSize 最大缓存条目数
 * @returns get/set/has/delete/clear
 */
export function createLruCache<K, V>(maxSize: number) {
  const map = new Map<K, V>()
  return {
    get(key: K): V | undefined {
      const v = map.get(key)
      if (v !== undefined) { map.delete(key); map.set(key, v) }
      return v
    },
    set(key: K, value: V): void {
      if (map.has(key)) map.delete(key)
      map.set(key, value)
      if (map.size > maxSize) {
        const first = map.keys().next().value
        map.delete(first)
      }
    },
    has(key: K): boolean { return map.has(key) },
    delete(key: K): void { map.delete(key) },
    clear(): void { map.clear() },
  }
}